{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop('fake', axis=1)  # axis=1 代表欄\n",
    "y = df['fake']\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute=None, threshold=None, value=None, left=None, right=None):\n",
    "        \"\"\"\n",
    "        初始化節點\n",
    "        :param attributete: 分割特徵的索引\n",
    "        :param threshold: 分割的閾值\n",
    "        :param value: 叶子节点的值（类别）\n",
    "        :param left: 左子树\n",
    "        :param right: 右子树\n",
    "        \"\"\"\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth=None, min_samples_split=None):\n",
    "        \"\"\"\n",
    "        初始化決策樹\n",
    "        :param max_depth: 樹的最大深度\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        計算entropy\n",
    "        :param y: 目標變量\n",
    "        :return: entropy\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)  # 計算每個類別的機率\n",
    "        # 利用講義公式計算entropy\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        找到最佳分割點\n",
    "        :param X: 特徵變量\n",
    "        :param y: 目標變量\n",
    "        :return: 最佳分割特徵的索引和閾值\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "        print(\"importance x(m,n)\", X.shape)\n",
    "        num_attributes = n\n",
    "        min_entropy = float('inf')\n",
    "        best_attribute, best_threshold = None, None\n",
    "\n",
    "        for attribute in range(num_attributes):\n",
    "            thresholds = np.unique(X[:, attribute])\n",
    "            for threshold in thresholds: # 對每個閾值計算entropy，找出擁有最小entropy的閾值\n",
    "                left_indices = X[:, attribute] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "\n",
    "                left_entropy = self.entropy(y[left_indices])\n",
    "                right_entropy = self.entropy(y[right_indices])\n",
    "\n",
    "                entropy = (len(y[left_indices]) * left_entropy + len(y[right_indices]) * right_entropy) / len(y)\n",
    "\n",
    "                # importance function \n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy = entropy\n",
    "                    best_attribute = attribute\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "        return best_attribute, best_threshold\n",
    "\n",
    "    def Decision_Tree_Learning(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        建立決策樹\n",
    "        :param X: 特徵變量\n",
    "        :param y: 目標變量\n",
    "        :param depth: 樹的深度\n",
    "        :return: 樹的根節點\n",
    "        \"\"\"\n",
    "        if self.max_depth is not None and depth == self.max_depth or len(set(y)) == 1:\n",
    "            # 改變樹高 -> 如果樹的深度等於max_depth，則停止分割\n",
    "            print(\"interrupt 達到最大深度\")\n",
    "            return Node(value=max(set(y), key=list(y).count))\n",
    "        if self.min_samples_split is not None and len(y) < self.min_samples_split:\n",
    "            # 剪枝 -> 如果樣本數小於min_samples_split，則停止分割\n",
    "            print(\"interrupt 達到最小樣本數\")\n",
    "            return Node(value=max(set(y), key=list(y).count))\n",
    "        \n",
    "        attribute, threshold = self.best_split(X, y)\n",
    "        print(\"best attribute\", attribute)\n",
    "        print(\"best threshold\", threshold)\n",
    "        \n",
    "        if attribute is None:\n",
    "            print(\"interrupt 找不到最佳分割點\")\n",
    "            return Node(value=max(set(y), key=list(y).count))\n",
    "\n",
    "        # 判斷左右子樹\n",
    "        left_indices = X[:, attribute] <= threshold \n",
    "        print(\"length of left 資料量\", len(X[left_indices]))\n",
    "        right_indices = ~left_indices\n",
    "        print(\"length of right 資料量\", len(X[right_indices]))\n",
    "        print(\"進入左子樹\")\n",
    "        left_subtree = self.Decision_Tree_Learning( X[left_indices], y[left_indices], depth + 1)\n",
    "        print(\"進入右子樹\")\n",
    "        right_subtree = self.Decision_Tree_Learning(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return Node(attribute=attribute, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        擬合模型\n",
    "        :param X: 特徵變量\n",
    "        :param y: 目標變量\n",
    "        \"\"\"\n",
    "        self.tree = self.Decision_Tree_Learning(X, y)\n",
    "\n",
    "    def predict_sample(self, tree, sample):\n",
    "        \"\"\"\n",
    "        預測單個樣本\n",
    "        :param tree: 決策樹\n",
    "        :param sample: 單個樣本\n",
    "        :return: 預測結果\n",
    "        \"\"\"\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        if sample[tree.attribute] <= tree.threshold:\n",
    "            return self.predict_sample(tree.left, sample)\n",
    "        else:\n",
    "            return self.predict_sample(tree.right, sample)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        預測多個樣本\n",
    "        :param X: 特徵變量\n",
    "        :return: 預測結果\n",
    "        \"\"\"\n",
    "        return np.array([self.predict_sample(self.tree, sample) for sample in X])\n",
    "\n",
    "    # def importance(self, X, y):\n",
    "    #     \"\"\"\n",
    "    #     計算特徵重要性\n",
    "    #     :param X: 特徵變量\n",
    "    #     :param y: 目標變量\n",
    "    #     :return: 特徵重要性\n",
    "    #     \"\"\"\n",
    "    #     attribute_importance = np.zeros(X.shape[1])\n",
    "    #     total_samples = len(y)\n",
    "\n",
    "    #     for attribute in range(X.shape[1]):\n",
    "    #         permuted_X = X.copy()\n",
    "    #         np.random.shuffle(permuted_X[:, attribute])\n",
    "    #         y_pred = self.predict(permuted_X)\n",
    "    #         accuracy = np.sum(y_pred == y) / total_samples\n",
    "    #         attribute_importance[attribute] = accuracy\n",
    "\n",
    "    #     return attribute_importance\n",
    "\n",
    "    # def plurality_value(self, y):\n",
    "    #     \"\"\"\n",
    "    #     找出最多數量的類別\n",
    "    #     :param y: 目標變量\n",
    "    #     :return: 最多數量的類別\n",
    "    #     \"\"\"\n",
    "    #     unique_classes, counts = np.unique(y, return_counts=True)  # 找出所有類別和數量\n",
    "    #     max_count = np.max(counts)  # 找出最多數量的類別\n",
    "    #     plurality_values = unique_classes[counts == max_count]\n",
    "    #     return plurality_values\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        計算準確率\n",
    "        :param y_true: 真實值\n",
    "        :param y_pred: 預測值\n",
    "        :return: 準確率\n",
    "        \"\"\"\n",
    "        return np.sum(y_true == y_pred) / len(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importance x(m,n) (460, 11)\n",
      "attribute 9\n",
      "threshold 97.0\n",
      "length of left 資料量 206\n",
      "length of right 資料量 254\n",
      "進入左子樹\n",
      "importance x(m,n) (206, 11)\n",
      "attribute 1\n",
      "threshold 0.19\n",
      "length of left 資料量 75\n",
      "length of right 資料量 131\n",
      "進入左子樹\n",
      "importance x(m,n) (75, 11)\n",
      "attribute 9\n",
      "threshold 57.0\n",
      "length of left 資料量 61\n",
      "length of right 資料量 14\n",
      "進入左子樹\n",
      "importance x(m,n) (61, 11)\n",
      "attribute 0\n",
      "threshold 0.0\n",
      "length of left 資料量 40\n",
      "length of right 資料量 21\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (21, 11)\n",
      "attribute 2\n",
      "threshold 1.0\n",
      "length of left 資料量 16\n",
      "length of right 資料量 5\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (14, 11)\n",
      "attribute 5\n",
      "threshold 10.0\n",
      "length of left 資料量 10\n",
      "length of right 資料量 4\n",
      "進入左子樹\n",
      "importance x(m,n) (10, 11)\n",
      "attribute 1\n",
      "threshold 0.0\n",
      "length of left 資料量 8\n",
      "length of right 資料量 2\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (254, 11)\n",
      "attribute 1\n",
      "threshold 0.24\n",
      "length of left 資料量 217\n",
      "length of right 資料量 37\n",
      "進入左子樹\n",
      "importance x(m,n) (217, 11)\n",
      "attribute 0\n",
      "threshold 0.0\n",
      "length of left 資料量 9\n",
      "length of right 資料量 208\n",
      "進入左子樹\n",
      "importance x(m,n) (9, 11)\n",
      "attribute 5\n",
      "threshold 0.0\n",
      "length of left 資料量 8\n",
      "length of right 資料量 1\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (208, 11)\n",
      "attribute 9\n",
      "threshold 505.0\n",
      "length of left 資料量 82\n",
      "length of right 資料量 126\n",
      "進入左子樹\n",
      "importance x(m,n) (82, 11)\n",
      "attribute 10\n",
      "threshold 689.0\n",
      "length of left 資料量 73\n",
      "length of right 資料量 9\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (126, 11)\n",
      "attribute 8\n",
      "threshold 4.0\n",
      "length of left 資料量 3\n",
      "length of right 資料量 123\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (37, 11)\n",
      "attribute 5\n",
      "threshold 9.0\n",
      "length of left 資料量 25\n",
      "length of right 資料量 12\n",
      "進入左子樹\n",
      "importance x(m,n) (25, 11)\n",
      "attribute 8\n",
      "threshold 7.0\n",
      "length of left 資料量 15\n",
      "length of right 資料量 10\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (10, 11)\n",
      "attribute 1\n",
      "threshold 0.31\n",
      "length of left 資料量 2\n",
      "length of right 資料量 8\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (12, 11)\n",
      "attribute 9\n",
      "threshold 158.0\n",
      "length of left 資料量 2\n",
      "length of right 資料量 10\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "importance x(m,n) (10, 11)\n",
      "attribute 2\n",
      "threshold 0.0\n",
      "length of left 資料量 2\n",
      "length of right 資料量 8\n",
      "進入左子樹\n",
      "interrupt 達到最大深度\n",
      "進入右子樹\n",
      "interrupt 達到最大深度\n",
      "Test Accuracy: 0.8706896551724138\n"
     ]
    }
   ],
   "source": [
    "# 加入訓練資料\n",
    "model = DecisionTree(max_depth=5, min_samples_split=5)\n",
    "model.fit(train_data.values, train_labels.values)\n",
    "y_pred = model.predict(test_data.values)\n",
    "print('Test Accuracy:', model.accuracy(test_labels.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0 attribute 9 threshold 97.0\n",
      "depth 1 attribute 1 threshold 0.19\n",
      "depth 2 attribute 9 threshold 57.0\n",
      "depth 3 attribute 0 threshold 0.0\n",
      "END depth 4 1\n",
      "depth 4 attribute 2 threshold 1.0\n",
      "depth 5 attribute 8 threshold 3.0\n",
      "END depth 6 1\n",
      "END depth 6 1\n",
      "depth 5 attribute 2 threshold 2.0\n",
      "END depth 6 0\n",
      "END depth 6 1\n",
      "depth 3 attribute 5 threshold 10.0\n",
      "depth 4 attribute 1 threshold 0.0\n",
      "depth 5 attribute 9 threshold 66.0\n",
      "END depth 6 1\n",
      "END depth 6 0\n",
      "END depth 5 0\n",
      "END depth 4 0\n",
      "END depth 2 1\n",
      "depth 1 attribute 1 threshold 0.24\n",
      "depth 2 attribute 0 threshold 0.0\n",
      "depth 3 attribute 5 threshold 0.0\n",
      "END depth 4 1\n",
      "END depth 4 0\n",
      "depth 3 attribute 9 threshold 505.0\n",
      "depth 4 attribute 10 threshold 689.0\n",
      "depth 5 attribute 7 threshold 0.0\n",
      "END depth 6 0\n",
      "END depth 6 0\n",
      "depth 5 attribute 8 threshold 26.0\n",
      "END depth 6 1\n",
      "END depth 6 0\n",
      "depth 4 attribute 8 threshold 4.0\n",
      "END depth 5 0\n",
      "END depth 5 0\n",
      "depth 2 attribute 5 threshold 9.0\n",
      "depth 3 attribute 8 threshold 7.0\n",
      "END depth 4 1\n",
      "depth 4 attribute 1 threshold 0.31\n",
      "END depth 5 0\n",
      "depth 5 attribute 2 threshold 0.0\n",
      "END depth 6 0\n",
      "END depth 6 1\n",
      "depth 3 attribute 9 threshold 158.0\n",
      "END depth 4 1\n",
      "depth 4 attribute 2 threshold 0.0\n",
      "END depth 5 0\n",
      "END depth 5 0\n"
     ]
    }
   ],
   "source": [
    "def _print_tree(tree):\n",
    "    \"\"\"\n",
    "    印出決策樹\n",
    "    :param model.tree: 決策樹\n",
    "    \"\"\"\n",
    "    def print_node(tree, depth=0):\n",
    "        if tree.value is not None:\n",
    "            print(\"END depth\", depth, tree.value)\n",
    "        else:\n",
    "            print(\"depth\", depth, \"attribute\" ,tree.attribute,\"threshold\" ,tree.threshold)\n",
    "            print_node(tree.left, depth + 1)\n",
    "            print_node(tree.right, depth + 1)\n",
    "\n",
    "    print_node(tree)\n",
    "_print_tree(model.tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
